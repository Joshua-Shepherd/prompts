# -*- mode: snippet -*-
# name: prompt
# group: pen
# key: pr
# expand-env: ((yas-indent-line 'fixed))
# --
# ---------------
# Functional keys
# ---------------

# A prompt which is in development will not be loaded by pen.el
in-development: yes

# A title for the prompt. This will become the function name.
title: "${1:title}"

# Increment this number every time you make a functional change.
# The test suite will only rerun if this version is incremented.
prompt-version: 1

# <:pp> defines a point where the following
# text is concatenated before the postprocessor
# is run.
# <1>, <2> etc. are where variables are substituted
# <1> is special because it may be the current selection
# <2> May be inferred from <1> via a prompt.
# This way, a function can be curried/beta-reduced to a function of 1 argument.
prompt: |+
    ${2:contents}

    <1> are like <2> in that

# Additional transformation of prompt after the template
prompt-filter: "sed -z 's/\\s\\+$//'"

# These are elisp String->String functions and run from pen.el
# It probably runs earlier than the preprocessors shell scripts
pen-preprocessors:
- "pen-pf-correct-grammar"

# The command passed to lm-complete
lm-command: "openai-complete.sh"

# The engine to be specified to the lm-command.
engine: "davinci"

# 0.0 = /r/ihadastroke
# 1.0 = /r/iamveryrandom
# Use 0.3-0.8
temperature: 0.8

# This is the max tokens requested from the LM
max-tokens: 60

# This number may go to the API if available.
# See top p sampling in the pen.el glossary.
# https://github.com/semiosis/pen.el/blob/master/glossary.txt
top-p: 1.0

# This number may go to the API and may
# improve the quality at the expense of making more
# requests.
best-of: 1

# Remove whitespace from the beginning of the response string
chomp-start: on

# Remove whitespace from the end of the response string
chomp-end: off

# Currently the OpenAI API can only accept one stop-sequence.
# So only the first one will be used by the API,
# but the completer script can make use the others.
stop-sequences:
- "\n"
- "\n\n"
- "##"

# Cache the function by default when running the prompt function
cache: on

# Names for the variables of the prompt function.
# The first variable may be captured by selection, rather than manually entered.
vars:
- "former"
- "latter"

# These are expressions run from within Pen to give the value for the variable
var-defaults:
- "(detect-language)"
- "(pen-preceding-text)"

# Examples of typical values for the variables
examples:
- "boysenberries"
- "strawberries"

# A preprocessor may be run on the variable inputs before entering the prompt
preprocessors:
- "sed 's/^/- /"
- "cat"

# Prompt function aliases
aliases:
- "asktutor"

# This is run on the completion results.
# It may be used to format the results
# before usage/insertion by emacs.
postprocessor: "sed 's/- //' | uniqnosort"

# The number of times the prompt is run when tested
n-test-runs: 5

# This is a script which may optionally be run on the prompt
# to prettify its output
prettifier: ttp

# Run it n times and combine the output. Default: 1
# This does not result in a list. It's usually a
# concatenation, but may use a different collation
# function for combining results.
n-collate: 10

# This for combining prompts with n-collate:
# It might be, for example, summarize, or uniqnosort.
pen-collation-postprocessor: "uniqnosort"

# Replace selected text. Yes if this is intended to be a text-replacement function.
filter: no

# Completion indicates that this prompt can be used as a company-mode completion function.
# When using this it is advisable to keep the default var-defaults unless you know what you're doing.
completion: on

# --------
# Doc keys
# --------

# A TODO list.
todo:
- Finish this prompt.

# A list of design patterns used.
# This may be a url or the name of a pattern.
design-patterns:
- multiplex
- "https://generative.ink/posts/methods-of-prompt-programming/"

# Possible other names for this prompt.
future-titles:
- Get code snippet
- Get snippet

# Aims for developing this prompt.
aims:
- More abstractive rewording

# Function documentation.
doc: "Given ... ${1:title}"

# For documentation that falls outside of todo, aims, doc, etc.
notes: "rlprompt is used here outside of pen.el"

# A list of problems with the prompt.
issue:
- "Struggles with the latter columns."

# A list of paths to previous prompts
past-versions:
- deprecated/pick-up-line.prompt

# A list of external services that provide a service function to this prompt
external-related:
- "https://paraphrasing-tool.com/"